# 海量数据处理

## 如何从大量的 URL 中找出相同的 URL？

给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。

每个 URL 占 64B，那么 50 亿个 URL 占用的空间大小约为 320GB。

1. 外排序

	在内存外面的排序，因为当要处理的数据量很大，而不能一次装入内存时，此时只能放在读写较慢的外存储器（通常是硬盘）上。

	外排序通常采用的是一种 *排序-归并* 的方法。

	* 排序阶段，先读入能放在内存中的数据量，将其排序输出到一个临时文件，依此进行，将待排序数据组织为多个有序的临时文件
	* 归并阶段，将临时文件组合为一个大的有序文件，也即排序结果
	
	采用 *排序-归并* 方法，复杂度是 O(nlogn)，但是因为外排序的使用的 k 路归并的 k 一般都很大，比如 k=1024，那么 log(k, 50亿) 实际上也就是3层，所以最终接近于 O(n) 。
	
2. 分治

	把一个文件中的 URL 按照某个特征划分为多个小文件，使得每个小文件大小不超过 4G，这样就可以把这个小文件读到内存中进行处理了。
	
	> 首先遍历文件 a，对遍历到的 URL 求 hash(URL) % 1000 ，根据计算结果把遍历到的 URL 存储到 a0, a1, a2, ..., a999，这样每个大小约为 300MB。使用同样的方法遍历文件 b，把文件 b 中的 URL 分别存储到文件 b0, b1, b2, ..., b999 中。这样处理过后，所有可能相同的 URL 都在对应的小文件中，即 a0 对应 b0, ..., a999 对应 b999，不对应的小文件不可能有相同的 URL。那么接下来，我们只需要求出这 1000 对小文件中相同的 URL 就好了。
	> 接着遍历 ai( i∈[0,999] )，把 URL 存储到一个 HashSet 集合中。然后遍历 bi 中每个 URL，看在 HashSet 集合中是否存在，若存在，说明这就是共同的 URL，可以把这个 URL 保存到一个单独的文件中。
	
	采用 *Hash-Hash* 方法，复杂度 O(n) 。

3. 前缀树

	一般而言，URL 的长度差距不会不大，而且前面几个字符，绝大部分相同。这种情况下，非常适合使用字典树（trie tree） 这种数据结构来进行存储，降低存储成本的同时，提高查询效率。
	
## 如何从大量数据中找出高频词？

有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。

1. 分治

	分治拆小文件 + HashMap算频数 + 小顶堆TopN

## 如何找出某一天访问百度网站最多的 IP？

现有海量日志数据保存在一个超大文件中，该文件无法直接读入内存，要求从中提取某天访问百度次数最多的那个 IP。

1. 分治

	取IP + 分治拆小文件 + HashMap算频数 + 小顶堆TopN

## 如何在大量的数据中找出不重复的整数？

在 2.5 亿个整数中找出不重复的整数。内存不足以容纳这 2.5 亿个整数。

1. 分治

	分治拆小文件 + HashSet/HashMap找不重复 + 合并

2. 位图
	
	假设 int 整数占用 4B，即 32bit，那么我们可以表示的整数的个数为 2^32。用 2 个 bit 来表示各个数字的状态
	
	* 00 表示这个数字没出现过
	* 01 表示这个数字出现过一次（即为题目所找的不重复整数）
	* 10 表示这个数字出现了多次

	这 232 个整数，总共所需内存为 232*2b=1GB。因此，当可用内存超过 1GB 时，可以采用位图法。
	
	但题目中，内存不足以容纳这 2.5 亿个整数，即 0.25G * 4B = 1GB，不适合用位图。
	
## 如何在大量的数据中判断一个数是否存在？

给定 40 亿个不重复的没排过序的 unsigned int 型整数，然后再给定一个数，如何快速判断这个数是否在这 40 亿个整数当中？

1. 分治

2. 位图

	unsigned int 数字的范围是 [0, 1 << 32)，我们用 1<<32=4,294,967,296 个 bit 来表示每个数字。初始位均为 0，那么总共需要内存：4,294,967,296b≈512M。

## 如何查询最热门的查询串？

搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询串的长度不超过 255 字节。

假设目前有 1000w 个记录（这些查询串的重复度比较高，虽然总数是 1000w，但如果除去重复后，则不超过 300w 个）。请统计最热门的 10 个查询串，要求使用的内存不能超过 1G。（一个查询串的重复度越高，说明查询它的用户越多，也就越热门。）

每个查询串最长为 255B，1000w 个串需要占用 约 2.55G 内存，因此，我们无法将所有字符串全部读入到内存中处理。

1. 分治

2. HashMap + 小顶堆TopN

	虽然字符串总数比较多，但去重后不超过 300w，因此，可以考虑把所有字符串及出现次数保存在一个 HashMap 中，所占用的空间为 300w*(255+4)≈777M（其中，4 表示整数占用的 4 个字节）。由此可见，1G 的内存空间完全够用。
	接着遍历 map，构建一个 10 个元素的小顶堆，若遍历到的字符串的出现次数大于堆顶字符串的出现次数，则进行替换，并将堆调整为小顶堆。

3. 前缀树

	这些字符串有大量相同前缀时，可以考虑使用前缀树来统计字符串出现的次数，树的结点保存字符串出现次数，0 表示没有出现。
	
	在遍历字符串时，在前缀树中查找，如果找到，则把结点中保存的字符串次数加 1，否则为这个字符串构建新结点，构建完成后把叶子结点中字符串的出现次数置为 1。

	最后依然使用小顶堆来对字符串的出现次数进行排序。

## 如何统计不同电话号码的个数？

已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。

共 1G 个号码，每个号码用一个 bit 表示，则需要内存 100M 。

1. 位图

## 如何从 5 亿个数中找出中位数？

从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 (N+1)/2 个数；当样本数为偶数时，中位数为 第 N/2 个数与第 1+N/2 个数的均值。

如果这道题没有内存大小限制，则可以把所有数读到内存中排序后找出中位数。但是最好的排序算法的时间复杂度都为 O(NlogN) 。需要使用其他方法。

1. 大顶堆 + 小顶堆
	
	维护两个堆，一个大顶堆，一个小顶堆。大顶堆中最大的数小于等于小顶堆中最小的数；保证这两个堆中的元素个数的差不超过 1。

	若数据总数为偶数，当这两个堆建好之后，中位数就是这两个堆顶元素的平均值。当数据总数为奇数时，根据两个堆的大小，中位数一定在数据多的堆的堆顶。

	这种方法，需要把所有数据都加载到内存中。当数据量很大时，就不能这样了，因此，这种方法适用于数据量较小的情况。5 亿个数，每个数字占用 4B，总共需要 2G 内存。如果可用内存不足 2G，就不能使用这种方法了。
	
2. 分治

	对于这道题，顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为 1，则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）。

	划分之后，可以非常容易地知道中位数是在 f0 还是 f1 中。假设 f1 中有 1 亿个数，那么中位数一定在 f0 中，且是在 f0 中，从小到大排列的第 1.5 亿个数与它后面的一个数的平均值。

	对于 f0 可以用次高位的二进制继续将文件一分为二，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。

## 如何按照 query 的频度排序？

有 10 个文件，每个文件大小为 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求按照 query 的频度排序。

如果 query 的重复度比较大，可以考虑一次性把所有 query 读入内存中处理；如果 query 的重复率不高，那么可用内存不足以容纳所有的 query，这时候就需要采用分治法或其他的方法来解决。

1. HashMap

	适合重复率高。
	
2. 分治

	Hash + 统计频数 + 合并 + 外排序所有文件

## 如何找出排名前 500 的数？

有 20 个数组，每个数组有 500 个元素，并且有序排列。如何在这 20*500 个数中找出前 500 的数？

假设数组降序排列

1. 堆排序

	建立大顶堆，堆的大小为数组的个数，即为 20，把每个数组最大的值存到堆中。
	删除堆顶元素，保存到另一个大小为 500 的数组中，然后向大顶堆插入删除的元素所在数组的下一个元素。
	重复上面的步骤，直到删除完第 500 个元素，也即找出了最大的前 500 个数。

